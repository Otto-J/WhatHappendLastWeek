import { Elysia } from "elysia";
import { getLastWeeksRssUpdates } from "../scripts/lastWeek";
import { writeFile, mkdir, readFile } from "fs/promises";
import { existsSync, createWriteStream } from "fs";
import path from "path";
import { getLastWeek } from "./utils/date";
import { chunkArray } from "./utils/array";
import { pipeline } from "stream";
import { promisify } from "util";
// @ts-expect-error: jstoxml æ²¡æœ‰ç±»å‹å£°æ˜
import { toXML } from "jstoxml";
import debug from "debug";

const RESULTS_DIR = path.resolve(process.cwd(), "results");
const MEDIA_DIR = path.resolve(process.cwd(), "media");

const app = new Elysia()
  .post("/lastweek", async (ctx) => {
    try {
      // å…ˆè·å–æœ¬å‘¨ weekNumber
      const { weekNumber } = getLastWeek();

      const filePath = path.join(RESULTS_DIR, `${weekNumber}.json`);
      // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      if (existsSync(filePath)) {
        // ç›´æ¥è¯»å–å¹¶è¿”å›
        const fileContent = await readFile(filePath, "utf-8");
        const json = JSON.parse(fileContent);
        return {
          status: true,
          file: `${weekNumber}.json`,
          msg: "å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›",
          ...json,
        };
      }
      // è·å–æ•°æ®
      const result = await getLastWeeksRssUpdates(weekNumber);
      // ç¡®ä¿ results ç›®å½•å­˜åœ¨
      if (!existsSync(RESULTS_DIR)) {
        await mkdir(RESULTS_DIR);
      }
      // å†™å…¥æ–‡ä»¶
      await writeFile(filePath, JSON.stringify(result, null, 2), "utf-8");
      return {
        status: true,
        file: `${weekNumber}.json`,
        msg: "å†™å…¥æˆåŠŸ",
        ...result,
      };
    } catch (e) {
      return {
        status: false,
        msg:
          typeof e === "object" && e && "message" in e
            ? (e as any).message
            : String(e),
      };
    }
  })
  .get("/", () => "Hello Elysia")
  .post("/fetchMp3", async (ctx) => {
    const log = debug("fetchMp3");
    log("æ”¶åˆ° fetchMp3 è¯·æ±‚", ctx.body);
    try {
      const week =
        (ctx.body && (ctx.body as any).weekNumber) ?? getLastWeek().weekNumber;
      log("ä½¿ç”¨çš„ weekNumber", week);
      const resultFile = path.join(RESULTS_DIR, `${week}.json`);
      let json;
      if (existsSync(resultFile)) {
        log("ç»“æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¯»å–", resultFile);
        json = JSON.parse(await readFile(resultFile, "utf-8"));
      } else {
        log("ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè°ƒç”¨ /lastweek æ¥å£è·å–æ•°æ®");
        const res = await fetch("http://localhost:3000/lastweek", {
          method: "POST",
        });
        log("ok è°ƒç”¨ /lastweek æ¥å£è·å–æ•°æ®");
        json = await res.json();
      }
      const { results } = json;
      if (!results) {
        log("æ—  results æ•°æ®");
        return { status: false, msg: "æ—  results æ•°æ®" };
      }
      // è¿‡æ»¤æ‰€æœ‰ media
      let tasks: {
        feedTitle: string;
        itemTitle: string;
        media: string;
        itemLink: string;
      }[] = [];
      for (const feed of results) {
        for (const item of feed.data) {
          if (item.media) {
            tasks.push({
              feedTitle: feed.feedTitle,
              itemTitle: item.itemTitle,
              media: item.media,
              itemLink: item.itemLink,
            });
          }
        }
      }
      log(`å…±æ‰¾åˆ° ${tasks.length} ä¸ª media ä¸‹è½½ä»»åŠ¡`);
      // åªåˆ†ç»„ media url
      const chunked = chunkArray(
        tasks.map((t) => t.media),
        1
      );
      const mediaDir = path.join(MEDIA_DIR, String(week));
      if (!existsSync(mediaDir)) {
        log("media ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»º", mediaDir);
        await mkdir(mediaDir, { recursive: true });
      }
      let success = [],
        failed = [];
      for (const group of chunked) {
        log(`å¼€å§‹ä¸‹è½½åˆ†ç»„: ${group}`);
        const groupResults = await Promise.all(
          group.map(async (media) => {
            const task = tasks.find((t) => t.media === media);
            if (!task) {
              log("æœªæ‰¾åˆ°åŸå§‹ä¿¡æ¯", media);
              return { media, status: "failed", error: "æœªæ‰¾åˆ°åŸå§‹ä¿¡æ¯" };
            }
            const { feedTitle, itemTitle } = task!;
            const fileName = `${sanitizeFileName(
              feedTitle
            )}_${week}_${sanitizeFileName(itemTitle)}`;
            const ext = media.split(".").pop()?.split("?")[0] || "mp3";
            const filePath = path.join(mediaDir, `${fileName}.${ext}`);
            if (existsSync(filePath)) {
              log("æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½", filePath);
              return { feedTitle, itemTitle, media, status: "skipped" };
            }
            try {
              log("å¼€å§‹ä¸‹è½½", media, "åˆ°", filePath);
              await downloadFile(media, filePath);
              log("ä¸‹è½½æˆåŠŸ", filePath);
              return { feedTitle, itemTitle, media, status: "success" };
            } catch (e) {
              log("ä¸‹è½½å¤±è´¥", media, e);
              return {
                feedTitle,
                itemTitle,
                media,
                status: "failed",
                error: String(e),
              };
            }
          })
        );
        for (const r of groupResults) {
          if (r.status === "success" || r.status === "skipped") success.push(r);
          else failed.push(r);
        }
      }
      log("ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸï¼š", success.length, "å¤±è´¥ï¼š", failed.length);
      return { status: true, week, success, failed };
    } catch (e) {
      log("fetchMp3 å¤„ç†å¼‚å¸¸", e);
      return { status: false, msg: String(e) };
    }
  })
  .get("/rss", async (ctx) => {
    try {
      // è·å–ä¸Šä¸€å‘¨ weekNumber
      const { weekNumber } = getLastWeek();
      const filePath = path.join(RESULTS_DIR, `${weekNumber}.json`);
      let json;
      if (existsSync(filePath)) {
        json = JSON.parse(await readFile(filePath, "utf-8"));
      } else {
        // å…¼å®¹é¦–æ¬¡æ— ç¼“å­˜
        const result = await getLastWeeksRssUpdates(weekNumber);
        json = result;
        await writeFile(filePath, JSON.stringify(result, null, 2), "utf-8");
      }
      // æ„é€  RSS 2.0 ç»“æ„
      const rssObj = {
        _name: "rss",
        _attrs: {
          version: "2.0",
          "xmlns:itunes": "http://www.itunes.com/dtds/podcast-1.0.dtd",
        },
        _content: {
          channel: [
            { title: "What Happened Last Week" },
            { link: "https://your-domain.com/rss" },
            { language: "zh-cn" },
            {
              description: `æ’­å®¢å‘¨æŠ¥ï¼Œå‘¨æ•°ï¼š${json.weekNumber}ï¼Œèµ·å§‹ï¼š${json.startOfWeek}`,
            },
            // å¯é€‰: { "itunes:author": "What Happened Last Week" },
            ...json.results.flatMap((feed: any) =>
              (feed.data as any[]).map((item: any) => ({
                item: {
                  title: item.itemTitle,
                  description: item.itemTitle,
                  ...(item.media
                    ? {
                        enclosure: {
                          _attrs: {
                            url: item.media,
                            type: "audio/mpeg",
                          },
                        },
                      }
                    : {}),
                  "itunes:author": feed.feedTitle,
                  // å¯é€‰: pubDate, guid ç­‰
                },
              }))
            ),
          ],
        },
      };
      const xml = toXML(rssObj, { header: true, indent: "  " });
      ctx.set.headers["content-type"] = "application/xml; charset=utf-8";
      return xml;
    } catch (e) {
      ctx.set.status = 500;
      return `RSS ç”Ÿæˆå¤±è´¥: ${e}`;
    }
  })
  .listen(3000);

console.log(
  `ğŸ¦Š Elysia is running at ${app.server?.hostname}:${app.server?.port}`
);

function sanitizeFileName(str: string) {
  // åªä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—ã€-ã€_ï¼Œç©ºæ ¼è½¬-ï¼Œå…¶ä»–å»æ‰
  return str
    .replace(/\s+/g, "-")
    .replace(/[^\u4e00-\u9fa5\w\-]/g, "")
    .replace(/-+/g, "-");
}

const streamPipeline = promisify(pipeline);

async function downloadFile(url: string, dest: string) {
  const res = await fetch(url);
  if (!res.ok || !res.body) throw new Error(`ä¸‹è½½å¤±è´¥: ${res.statusText}`);

  const total = Number(res.headers.get("content-length")) || 0;
  let downloaded = 0;
  let lastLogged = 0;
  let lastPrintTime = Date.now();

  // Node fetch è¿”å›çš„æ˜¯ web ReadableStreamï¼Œéœ€è¦è½¬æˆ Node.js Readable
  const nodeStream = (res.body as any).pipe
    ? res.body
    : require("stream").Readable.fromWeb(res.body);

  const fileStream = createWriteStream(dest);

  nodeStream.on("data", (chunk: Buffer) => {
    downloaded += chunk.length;
    const now = Date.now();
    let shouldPrint = false;
    if (now - lastPrintTime >= 2000) {
      shouldPrint = true;
      lastPrintTime = now;
    }
    if (total) {
      const percent = Math.floor((downloaded / total) * 100);
      // æ¯ 10% æˆ–æ¯ 1MB æ‰“å°ä¸€æ¬¡ï¼Œå¹¶ä¸”æ¯2ç§’æœ€å¤šæ‰“å°ä¸€æ¬¡
      if (
        (percent >= lastLogged + 10 ||
          downloaded - lastLogged >= 1024 * 1024) &&
        shouldPrint
      ) {
        lastLogged = percent;
        console.log(
          `ä¸‹è½½è¿›åº¦: ${percent}% (${(downloaded / 1024 / 1024).toFixed(2)}MB/${(
            total /
            1024 /
            1024
          ).toFixed(2)}MB)`
        );
      }
    } else {
      // æ²¡æœ‰ content-length æ—¶ï¼Œæ¯ 1MB æ‰“å°ä¸€æ¬¡ï¼Œå¹¶ä¸”æ¯2ç§’æœ€å¤šæ‰“å°ä¸€æ¬¡
      if (downloaded - lastLogged >= 1024 * 1024 && shouldPrint) {
        lastLogged = downloaded;
        console.log(`å·²ä¸‹è½½: ${(downloaded / 1024 / 1024).toFixed(2)}MB`);
      }
    }
  });

  await streamPipeline(nodeStream, fileStream);
  console.log("ä¸‹è½½å®Œæˆ:", dest);
}
